
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://bk073.github.io/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://bk073.github.io/theme/pygments/friendly.min.css">


  <link rel="stylesheet" type="text/css" href="https://bk073.github.io/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://bk073.github.io/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://bk073.github.io/theme/font-awesome/css/solid.css">


    <link href="https://bk073.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bishwa Karki Atom">





<meta name="author" content="Bishwa Karki" />
<meta name="description" content="Importance of batch normalization" />
<meta name="keywords" content="pelican, markdown">


<meta property="og:site_name" content="Bishwa Karki"/>
<meta property="og:title" content="Batch Normalization"/>
<meta property="og:description" content="Importance of batch normalization"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://bk073.github.io/2020/07/batch-normalization/"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-07-15 06:42:00+05:45"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://bk073.github.io/author/bishwa-karki.html">
<meta property="article:section" content="Deep Learning"/>
<meta property="article:tag" content="pelican"/>
<meta property="article:tag" content="markdown"/>
<meta property="og:image" content="/images/profile.jpg">

  <title>Bishwa Karki &ndash; Batch Normalization</title>

</head>
<body class="light-theme">
  <aside>
    <div>
      <a href="https://bk073.github.io">
        <img src="/images/profile.jpg" alt="Bishwa Karki" title="Bishwa Karki">
      </a>

      <h1>
        <a href="https://bk073.github.io">Bishwa Karki</a>
      </h1>

<p>Trying to share what I learned</p>

      <nav>
        <ul class="list">


              <li>
                <a target="_self"
                   href="https://bk073.github.io/about/#about">
                  About
                </a>
              </li>
              <li>
                <a target="_self"
                   href="https://bk073.github.io/contact/#contact">
                  Contact
                </a>
              </li>

        </ul>
      </nav>

      <ul class="social">
          <li>
            <a  class="sc-github" href="https://github.com/bk073" target="_blank">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a  class="sc-envelope" href="mailto:karkeebishwa1@gmail.com" target="_blank">
              <i class="fas fa-envelope"></i>
            </a>
          </li>
          <li>
            <a  class="sc-linkedin" href="https://np.linkedin.com/in/bishwakarki" target="_blank">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://bk073.github.io">Home</a>

      <a href="/archives">Archives</a>
      <a href="/categories">Categories</a>
      <a href="/tags">Tags</a>

      <a href="https://bk073.github.io/feeds/all.atom.xml">Atom</a>

    </nav>

<article class="single">
  <header>
      
    <h1 id="batch-normalization">Batch Normalization</h1>
    <p>
      Posted on Wed 15 July 2020 in <a href="https://bk073.github.io/category/deep-learning.html">Deep Learning</a>

        &#8226; 2 min read
    </p>
  </header>


  <div>
    <p><strong> Why do we need batch norm ? </strong></p>
<p>Before going into batch norm, lets understand why do we really need it. 
During training deep neural networks the distribution of each layer's input changes, as the parameters changes in the previous layers. So this slow downs the learning by requiring lower learning rate and we have to be careful during parameter initializations. And makes the model harder to train with saturating non linearities. This condition is called <strong> covariance shift </strong>.
This problem is solved by batch normalization and allows us to use larger learning rate which makes training faster and can be less careful about parameter initialization. Batch normalization limits the covariate shift by normalizing the activation of each layer.</p>
<p>Batch normalization is similar to normalization technique we use in classic machine learning to decrease the variance between features. In deep learning, batch normalization normalizes output of each neuron in each hidden layer according to samples in the mini-batch.</p>
<p>x_normalized = (x - mean) / (standard deviation)</p>
<p>Here, mean and standard deviation are computed for particular mini-batch.</p>
<p><strong> What about normalization during inference ? </strong></p>
<p>So the process mentioned above is used during training, i.e we calculate the mean and standard deviation for each batch and process accordingly. So during inference we can't assume mini-batch. But we need to use all the techniques used to process input during training i.e we need the mean and standard deviation.</p>
<p>Once the network has been trained, we use the normalization:</p>
<p>x_normalized = (x - E[x])/ Sqrt(Var[x] + e)</p>
<p>Instead of using the expectation and variance over the population we use it over the mini-batchesto make the performance better.</p>
<p>We calculate on mini-batch of size m:</p>
<p>E[x] &lt;-- E_batch[mean_batch]
Var[x] &lt;-- (m/(m-1)) * E_batch[standard_deviation_batch]</p>
<p>Another way of estimating E[x] and Var[x] is exponentially weighted moving avergae over the mini-batch during training.</p>
<ul>
<li>
<p>References </p>
</li>
<li>
<p>https://arxiv.org/pdf/1502.03167.pdf</p>
</li>
</ul>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://bk073.github.io/tag/pelican.html">pelican</a>
      <a href="https://bk073.github.io/tag/markdown.html">markdown</a>
    </p>
  </div>





</article>

    <footer>
<p>&copy;  </p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Bishwa Karki ",
  "url" : "https://bk073.github.io",
  "image": "/images/profile.jpg",
  "description": ""
}
</script>


</body>
</html>